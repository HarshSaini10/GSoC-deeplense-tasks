{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efc0a5f-b0ba-408f-a94d-5f7b359d0728",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:07.740343Z",
     "iopub.status.busy": "2025-04-01T11:22:07.740059Z",
     "iopub.status.idle": "2025-04-01T11:22:15.788246Z",
     "shell.execute_reply": "2025-04-01T11:22:15.787532Z",
     "shell.execute_reply.started": "2025-04-01T11:22:07.740322Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import h5py as h5\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.models as models\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import os\n",
    "import csv\n",
    "import h5py\n",
    "from torchvision.models import resnet18\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n",
    "from PIL import Image\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9429dff5-ca79-4222-a1aa-9757f5f4602f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:15.789616Z",
     "iopub.status.busy": "2025-04-01T11:22:15.789230Z",
     "iopub.status.idle": "2025-04-01T11:22:16.040520Z",
     "shell.execute_reply": "2025-04-01T11:22:16.039730Z",
     "shell.execute_reply.started": "2025-04-01T11:22:15.789585Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_path = \"/kaggle/input/deeplense-task1/dataset/train\"\n",
    "train_imgs = {}\n",
    "for cat in os.listdir(train_path):\n",
    "    sub_path = os.path.join(train_path,cat)\n",
    "    imgs = []\n",
    "    for img_path in os.listdir(sub_path):\n",
    "        imgs.append(os.path.join(sub_path,img_path))\n",
    "    train_imgs[cat] = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80116091-e4f0-419c-926c-6af36515c4a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.042389Z",
     "iopub.status.busy": "2025-04-01T11:22:16.042169Z",
     "iopub.status.idle": "2025-04-01T11:22:16.162237Z",
     "shell.execute_reply": "2025-04-01T11:22:16.161482Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.042371Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "val_path = \"/kaggle/input/deeplense-task1/dataset/val\"\n",
    "val_imgs = {}\n",
    "for cat in os.listdir(val_path):\n",
    "    sub_path = os.path.join(val_path,cat)\n",
    "    imgs = []\n",
    "    for img_path in os.listdir(sub_path):\n",
    "        imgs.append(os.path.join(sub_path,img_path))\n",
    "    val_imgs[cat] = imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a03b89e2-4d20-499f-881b-526260e76dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.163701Z",
     "iopub.status.busy": "2025-04-01T11:22:16.163402Z",
     "iopub.status.idle": "2025-04-01T11:22:16.173891Z",
     "shell.execute_reply": "2025-04-01T11:22:16.173080Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.163672Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_rows = [(img_path, label) for label, img_paths in train_imgs.items() for img_path in img_paths]\n",
    "val_rows = [(img_path, label) for label, img_paths in val_imgs.items() for img_path in img_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47c005ff-8b31-4af1-aefa-be395156f8de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.174911Z",
     "iopub.status.busy": "2025-04-01T11:22:16.174723Z",
     "iopub.status.idle": "2025-04-01T11:22:16.196506Z",
     "shell.execute_reply": "2025-04-01T11:22:16.195733Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.174895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_rows, columns = ['img_path','label'])\n",
    "df_val = pd.DataFrame(val_rows, columns = ['img_path','label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8e0a1fd-cbc3-4d18-8088-8c572c46586b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.197536Z",
     "iopub.status.busy": "2025-04-01T11:22:16.197319Z",
     "iopub.status.idle": "2025-04-01T11:22:16.215466Z",
     "shell.execute_reply": "2025-04-01T11:22:16.214801Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.197519Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].map({'no':0, 'sphere':1, 'vort':2})\n",
    "df_val['label'] = df_val['label'].map({'no':0, 'sphere':1, 'vort':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93eb5713-d672-4be9-9f68-77ca22aac1a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.216624Z",
     "iopub.status.busy": "2025-04-01T11:22:16.216317Z",
     "iopub.status.idle": "2025-04-01T11:22:16.222107Z",
     "shell.execute_reply": "2025-04-01T11:22:16.221418Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.216592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Dataset(nn.Module):\n",
    "    def __init__(self,data,transform = None, train = True):\n",
    "        self.data = data\n",
    "        self.imgs = [np.load(img_path) for img_path in self.data['img_path']]\n",
    "        self.y = torch.tensor(self.data['label'], dtype = torch.long)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.imgs[idx].squeeze()[:,:,np.newaxis]\n",
    "        label = self.y[idx]\n",
    "        img = np.tile(img,(1,1,3))\n",
    "        if self.transform != None:\n",
    "            img = self.transform(image = img)[\"image\"]\n",
    "\n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1a898f2-47a9-464e-865d-8109957ef338",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.224210Z",
     "iopub.status.busy": "2025-04-01T11:22:16.224011Z",
     "iopub.status.idle": "2025-04-01T11:22:16.242340Z",
     "shell.execute_reply": "2025-04-01T11:22:16.241747Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.224194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_transform = A.Compose([\n",
    "    # A.RandomRotate90(p=0.5),\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    # A.VerticalFlip(p=0.5),\n",
    "    # A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=45, p=0.5),\n",
    "    # A.Normalize(mean=(0.485, 0.456, 0.406), \n",
    "    #             std=(0.229, 0.224, 0.225)),\n",
    "    # A.Resize(28,28),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    # A.Resize(28,28),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "463b3777-9471-4f33-a9ba-37d5cf50771b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:22:16.243357Z",
     "iopub.status.busy": "2025-04-01T11:22:16.243143Z",
     "iopub.status.idle": "2025-04-01T11:26:49.094988Z",
     "shell.execute_reply": "2025-04-01T11:26:49.094260Z",
     "shell.execute_reply.started": "2025-04-01T11:22:16.243333Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_dataset = Dataset(df_train, train_transform)\n",
    "val_dataset = Dataset(df_val, val_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07847dcd-b791-449a-b304-1be851fdd861",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T11:26:49.095979Z",
     "iopub.status.busy": "2025-04-01T11:26:49.095770Z",
     "iopub.status.idle": "2025-04-01T11:26:49.100069Z",
     "shell.execute_reply": "2025-04-01T11:26:49.099239Z",
     "shell.execute_reply.started": "2025-04-01T11:26:49.095961Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size = 32, shuffle = True, num_workers = 0)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 32, shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdca6fa6-4915-419b-be47-fe4f28d042eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:06:25.871968Z",
     "iopub.status.busy": "2025-04-01T14:06:25.871598Z",
     "iopub.status.idle": "2025-04-01T14:37:58.944887Z",
     "shell.execute_reply": "2025-04-01T14:37:58.943997Z",
     "shell.execute_reply.started": "2025-04-01T14:06:25.871942Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Training baseline variant ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/5 [Train - baseline]: 100%|██████████| 938/938 [01:19<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.9301, Train Acc 0.5249, Train AUC 0.7300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Val - baseline]: 100%|██████████| 235/235 [00:06<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss 0.6713, Val Acc 0.7104, Val AUC 0.8800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train - baseline]: 100%|██████████| 938/938 [01:19<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.5241, Train Acc 0.7903, Train AUC 0.9228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Val - baseline]: 100%|██████████| 235/235 [00:06<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss 0.3925, Val Acc 0.8533, Val AUC 0.9588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train - baseline]: 100%|██████████| 938/938 [01:19<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.3680, Train Acc 0.8616, Train AUC 0.9613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Val - baseline]: 100%|██████████| 235/235 [00:06<00:00, 34.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss 0.3160, Val Acc 0.8809, Val AUC 0.9721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train - baseline]: 100%|██████████| 938/938 [01:19<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.3036, Train Acc 0.8883, Train AUC 0.9732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Val - baseline]: 100%|██████████| 235/235 [00:06<00:00, 35.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss 0.2896, Val Acc 0.8925, Val AUC 0.9753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train - baseline]: 100%|██████████| 938/938 [01:19<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.2643, Train Acc 0.9051, Train AUC 0.9794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Val - baseline]: 100%|██████████| 235/235 [00:06<00:00, 35.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss 0.2587, Val Acc 0.9099, Val AUC 0.9799\n",
      "\n",
      "=== Training pde variant ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/5 [Train - pde]: 100%|██████████| 938/938 [01:22<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.9209, Train Acc 0.5326, Train AUC 0.7384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Val - pde]: 100%|██████████| 235/235 [00:06<00:00, 33.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss 0.6033, Val Acc 0.7504, Val AUC 0.8986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train - pde]: 100%|██████████| 938/938 [01:22<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.5187, Train Acc 0.7952, Train AUC 0.9244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Val - pde]: 100%|██████████| 235/235 [00:06<00:00, 33.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss 0.4014, Val Acc 0.8481, Val AUC 0.9569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train - pde]: 100%|██████████| 938/938 [01:22<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.3796, Train Acc 0.8571, Train AUC 0.9593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Val - pde]: 100%|██████████| 235/235 [00:06<00:00, 34.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss 0.3283, Val Acc 0.8801, Val AUC 0.9708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train - pde]: 100%|██████████| 938/938 [01:22<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.3131, Train Acc 0.8842, Train AUC 0.9718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Val - pde]: 100%|██████████| 235/235 [00:06<00:00, 33.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss 0.3337, Val Acc 0.8700, Val AUC 0.9735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train - pde]: 100%|██████████| 938/938 [01:22<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.2663, Train Acc 0.9035, Train AUC 0.9796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Val - pde]: 100%|██████████| 235/235 [00:06<00:00, 33.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss 0.2636, Val Acc 0.9071, Val AUC 0.9800\n",
      "\n",
      "=== Training energy variant ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/5 [Train - energy]: 100%|██████████| 938/938 [01:20<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.9193, Train Acc 0.5617, Train AUC 0.7597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Val - energy]: 100%|██████████| 235/235 [00:06<00:00, 34.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss 0.6053, Val Acc 0.7560, Val AUC 0.9093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train - energy]: 100%|██████████| 938/938 [01:20<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.5178, Train Acc 0.8061, Train AUC 0.9309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Val - energy]: 100%|██████████| 235/235 [00:06<00:00, 33.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss 0.3918, Val Acc 0.8621, Val AUC 0.9609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train - energy]: 100%|██████████| 938/938 [01:19<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.3876, Train Acc 0.8620, Train AUC 0.9619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Val - energy]: 100%|██████████| 235/235 [00:06<00:00, 34.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss 0.3777, Val Acc 0.8647, Val AUC 0.9715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train - energy]: 100%|██████████| 938/938 [01:20<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.3203, Train Acc 0.8924, Train AUC 0.9737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Val - energy]: 100%|██████████| 235/235 [00:06<00:00, 35.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss 0.2982, Val Acc 0.9035, Val AUC 0.9793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train - energy]: 100%|██████████| 938/938 [01:20<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.2740, Train Acc 0.9101, Train AUC 0.9809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Val - energy]: 100%|██████████| 235/235 [00:06<00:00, 35.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss 0.2796, Val Acc 0.9091, Val AUC 0.9811\n",
      "\n",
      "=== Training both variant ===\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/5 [Train - both]: 100%|██████████| 938/938 [01:22<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss 0.9904, Train Acc 0.4772, Train AUC 0.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 [Val - both]: 100%|██████████| 235/235 [00:06<00:00, 33.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss 0.7056, Val Acc 0.6996, Val AUC 0.8707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Train - both]: 100%|██████████| 938/938 [01:22<00:00, 11.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss 0.5457, Train Acc 0.7894, Train AUC 0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/5 [Val - both]: 100%|██████████| 235/235 [00:06<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss 0.3772, Val Acc 0.8639, Val AUC 0.9624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Train - both]: 100%|██████████| 938/938 [01:22<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss 0.3834, Train Acc 0.8610, Train AUC 0.9612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/5 [Val - both]: 100%|██████████| 235/235 [00:06<00:00, 34.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss 0.2993, Val Acc 0.8925, Val AUC 0.9760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Train - both]: 100%|██████████| 938/938 [01:22<00:00, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss 0.3047, Train Acc 0.8946, Train AUC 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/5 [Val - both]: 100%|██████████| 235/235 [00:06<00:00, 34.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss 0.3075, Val Acc 0.8956, Val AUC 0.9785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Train - both]: 100%|██████████| 938/938 [01:22<00:00, 11.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss 0.2679, Train Acc 0.9063, Train AUC 0.9807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/5 [Val - both]: 100%|██████████| 235/235 [00:06<00:00, 34.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss 0.2950, Val Acc 0.9012, Val AUC 0.9796\n",
      "\n",
      "Training and visualization complete. Check the 'model_plots' directory for results.\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"model_plots\", exist_ok=True)\n",
    "\n",
    "def get_pretrained_encoder(model_name, latent_dim, input_size=(3, 150, 150)):\n",
    "    if hasattr(models, model_name):\n",
    "        backbone = getattr(models, model_name)(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
    "    if model_name.startswith('efficientnet'):\n",
    "        encoder = backbone.features\n",
    "        encoder = nn.Sequential(\n",
    "            encoder,\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    elif model_name.startswith('densenet'):\n",
    "        encoder = nn.Sequential(\n",
    "            backbone.features,\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten()\n",
    "        )\n",
    "    else:\n",
    "        encoder = nn.Sequential(*list(backbone.children())[:-1], nn.Flatten())\n",
    "    dummy_input = torch.randn(1, *input_size)\n",
    "    with torch.no_grad():\n",
    "        dummy_output = encoder(dummy_input)\n",
    "    feature_dim = dummy_output.shape[1]\n",
    "    projection = nn.Linear(feature_dim, latent_dim)\n",
    "    return nn.Sequential(encoder, projection), feature_dim\n",
    "\n",
    "class AutoencoderClassifier(nn.Module):\n",
    "    def __init__(self, model_name=\"resnet18\", latent_dim=128, num_classes=3, input_size=(3, 150, 150)):\n",
    "        super(AutoencoderClassifier, self).__init__()\n",
    "        self.encoder, feature_dim = get_pretrained_encoder(model_name, latent_dim, input_size)\n",
    "        self.input_size = input_size\n",
    "        if model_name.startswith('efficientnet'):\n",
    "            backbone = getattr(models, model_name)(pretrained=True)\n",
    "            temp_encoder = backbone.features\n",
    "        elif model_name.startswith('densenet'):\n",
    "            backbone = getattr(models, model_name)(pretrained=True)\n",
    "            temp_encoder = nn.Sequential(backbone.features, nn.ReLU(inplace=True))\n",
    "        else:\n",
    "            backbone = getattr(models, model_name)(pretrained=True)\n",
    "            temp_encoder = nn.Sequential(*list(backbone.children())[:-2])\n",
    "        dummy_input = torch.randn(1, *input_size)\n",
    "        with torch.no_grad():\n",
    "            feature_map = temp_encoder(dummy_input)\n",
    "        self.feature_map_shape = feature_map.shape[1:]\n",
    "        num_decoder_features = self.feature_map_shape[0] * self.feature_map_shape[1] * self.feature_map_shape[2]\n",
    "        self.decoder_fc = nn.Linear(latent_dim, num_decoder_features)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Unflatten(1, self.feature_map_shape),\n",
    "            nn.ConvTranspose2d(self.feature_map_shape[0], 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 3, kernel_size=3, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        latent = self.encoder(x)\n",
    "        decoder_input = self.decoder_fc(latent)\n",
    "        reconstruction = self.decoder(decoder_input)\n",
    "        class_out = self.classifier(latent)\n",
    "        if reconstruction.shape[2:] != torch.Size([self.input_size[1], self.input_size[2]]):\n",
    "            reconstruction = nn.functional.interpolate(\n",
    "                reconstruction, \n",
    "                size=(self.input_size[1], self.input_size[2]), \n",
    "                mode='bilinear', \n",
    "                align_corners=False\n",
    "            )\n",
    "        return class_out, reconstruction, latent\n",
    "\n",
    "def compute_laplacian(images):\n",
    "    batch_size, channels, height, width = images.shape\n",
    "\n",
    "    sobel_x = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=torch.float32).to(images.device)\n",
    "    sobel_x = sobel_x.view(1, 1, 3, 3).repeat(channels, 1, 1, 1)\n",
    "    \n",
    "    sobel_y = torch.tensor([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=torch.float32).to(images.device)\n",
    "    sobel_y = sobel_y.view(1, 1, 3, 3).repeat(channels, 1, 1, 1)\n",
    "    \n",
    "    padding = nn.ReflectionPad2d(1)\n",
    "    padded_images = padding(images)\n",
    "    \n",
    "    grad_x = F.conv2d(padded_images, sobel_x.expand(channels, 1, 3, 3), groups=channels)\n",
    "    grad_y = F.conv2d(padded_images, sobel_y.expand(channels, 1, 3, 3), groups=channels)\n",
    "    \n",
    "    padded_grad_x = padding(grad_x)\n",
    "    padded_grad_y = padding(grad_y)\n",
    "    \n",
    "    grad_xx = F.conv2d(padded_grad_x, sobel_x.expand(channels, 1, 3, 3), groups=channels)\n",
    "    grad_yy = F.conv2d(padded_grad_y, sobel_y.expand(channels, 1, 3, 3), groups=channels)\n",
    "\n",
    "    laplacian = grad_xx + grad_yy\n",
    "    \n",
    "    return laplacian\n",
    "\n",
    "def train_variant(model, train_dataloader, val_dataloader, variant=\"baseline\", num_epochs=10, \n",
    "                 device='cuda', lambda_recon=1.0, lambda_pde=0.1, lambda_energy=0.1):\n",
    "    device = torch.device(device if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    cls_criterion = nn.CrossEntropyLoss()\n",
    "    recon_criterion = nn.MSELoss()\n",
    "\n",
    "    history = {\n",
    "        'train_loss': [], 'train_acc': [], 'train_auc': [],\n",
    "        'val_loss': [], 'val_acc': [], 'val_auc': [],\n",
    "        'component_losses': {'cls': [], 'recon': [], 'pde': [], 'energy': []}\n",
    "    }\n",
    "    \n",
    "    all_latents = []\n",
    "    all_labels = []\n",
    "    val_labels = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss, total, correct = 0.0, 0, 0\n",
    "        all_preds, all_labels_epoch = [], []\n",
    "        component_losses = {'cls': 0.0, 'recon': 0.0, 'pde': 0.0, 'energy': 0.0}\n",
    "        \n",
    "        for images, labels in tqdm(train_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Train - {variant}]\"):\n",
    "            images, labels = images.to(device).float(), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs, recon, latent = model(images)\n",
    "\n",
    "            cls_loss = cls_criterion(outputs, labels)\n",
    "            component_losses['cls'] += cls_loss.item() * images.size(0)\n",
    "  \n",
    "            recon_loss = recon_criterion(recon, images)\n",
    "            component_losses['recon'] += recon_loss.item() * images.size(0)\n",
    "\n",
    "            loss = cls_loss + lambda_recon * recon_loss\n",
    "\n",
    "            pde_loss = torch.tensor(0.0).to(device)\n",
    "            if variant in [\"pde\", \"both\"]:\n",
    "                laplacian = compute_laplacian(recon)\n",
    "                pde_loss = torch.mean(laplacian**2) \n",
    "                loss += lambda_pde * pde_loss\n",
    "                component_losses['pde'] += pde_loss.item() * images.size(0)\n",
    "   \n",
    "            energy_loss = torch.tensor(0.0).to(device)\n",
    "            if variant in [\"energy\", \"both\"]:\n",
    "                energy_loss = torch.mean((latent**2 - 1)**2) \n",
    "                loss += lambda_energy * energy_loss\n",
    "                component_losses['energy'] += energy_loss.item() * images.size(0)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item() * images.size(0)\n",
    "            _, preds = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            all_preds.extend(outputs.softmax(dim=1).detach().cpu().numpy())\n",
    "            all_labels_epoch.extend(labels.cpu().numpy())\n",
    "            \n",
    "        train_acc = correct / total\n",
    "        train_auc = roc_auc_score(all_labels_epoch, all_preds, multi_class='ovr')\n",
    "\n",
    "        for k in component_losses:\n",
    "            component_losses[k] /= total\n",
    "            history['component_losses'][k].append(component_losses[k])\n",
    "\n",
    "        history['train_loss'].append(total_loss / total)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['train_auc'].append(train_auc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Train Loss {total_loss/total:.4f}, Train Acc {train_acc:.4f}, Train AUC {train_auc:.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss, val_correct, total_val = 0.0, 0, 0\n",
    "        val_preds, val_labels_epoch = [], []\n",
    "        val_latents = []\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(val_dataloader, desc=f\"Epoch {epoch+1}/{num_epochs} [Val - {variant}]\"):\n",
    "                images, labels = images.to(device).float(), labels.to(device)\n",
    "                outputs, recon, latent = model(images)\n",
    "\n",
    "                if epoch == num_epochs - 1:\n",
    "                    val_latents.append(latent.cpu())\n",
    "                    val_labels.extend(labels.cpu().numpy())\n",
    "                \n",
    "                cls_loss = cls_criterion(outputs, labels)\n",
    "                recon_loss = recon_criterion(recon, images)\n",
    "\n",
    "                loss = cls_loss + lambda_recon * recon_loss\n",
    "                \n",
    "                if variant in [\"pde\", \"both\"]:\n",
    "                    laplacian = compute_laplacian(recon)\n",
    "                    pde_loss = torch.mean(laplacian**2)\n",
    "                    loss += lambda_pde * pde_loss\n",
    "                \n",
    "                if variant in [\"energy\", \"both\"]:\n",
    "                    energy_loss = torch.mean((latent**2 - 1)**2)\n",
    "                    loss += lambda_energy * energy_loss\n",
    "                \n",
    "                val_loss += loss.item() * images.size(0)\n",
    "                _, preds = outputs.max(1)\n",
    "                total_val += labels.size(0)\n",
    "                val_correct += preds.eq(labels).sum().item()\n",
    "                val_preds.extend(outputs.softmax(dim=1).cpu().numpy())\n",
    "                val_labels_epoch.extend(labels.cpu().numpy())\n",
    "        \n",
    "        val_acc = val_correct / total_val\n",
    "        val_auc = roc_auc_score(val_labels_epoch, val_preds, multi_class='ovr')\n",
    "\n",
    "        history['val_loss'].append(val_loss / total_val)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['val_auc'].append(val_auc)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}: Val Loss {val_loss/total_val:.4f}, Val Acc {val_acc:.4f}, Val AUC {val_auc:.4f}\")\n",
    "\n",
    "    if val_latents:\n",
    "        all_latents = torch.cat(val_latents, dim=0)\n",
    "        all_labels = np.array(val_labels)\n",
    "    \n",
    "    return model, history, all_latents, all_labels\n",
    "\n",
    "def plot_history(histories, variant_names, save_path=\"model_plots\"):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    ax = axes[0, 0]\n",
    "    for variant, history in zip(variant_names, histories):\n",
    "        ax.plot(history['train_loss'], label=f\"{variant} Train\")\n",
    "        ax.plot(history['val_loss'], label=f\"{variant} Val\", linestyle='--')\n",
    "    ax.set_title('Loss')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    ax = axes[0, 1]\n",
    "    for variant, history in zip(variant_names, histories):\n",
    "        ax.plot(history['train_acc'], label=f\"{variant} Train\")\n",
    "        ax.plot(history['val_acc'], label=f\"{variant} Val\", linestyle='--')\n",
    "    ax.set_title('Accuracy')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axes[1, 0]\n",
    "    for variant, history in zip(variant_names, histories):\n",
    "        ax.plot(history['train_auc'], label=f\"{variant} Train\")\n",
    "        ax.plot(history['val_auc'], label=f\"{variant} Val\", linestyle='--')\n",
    "    ax.set_title('ROC AUC')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('AUC')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    ax = axes[1, 1]\n",
    "    for component in ['cls', 'recon', 'pde', 'energy']:\n",
    "        if histories[-1]['component_losses'][component]: \n",
    "            ax.plot(histories[-1]['component_losses'][component], label=component)\n",
    "    ax.set_title(f'Component Losses ({variant_names[-1]})')\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_path}/learning_curves.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    plt.figure(figsize=(14, 8))\n",
    "    for i, (variant, history) in enumerate(zip(variant_names, histories)):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        for component in ['cls', 'recon', 'pde', 'energy']:\n",
    "            if history['component_losses'][component]:\n",
    "                plt.plot(history['component_losses'][component], label=component)\n",
    "        plt.title(f'Component Losses ({variant})')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_path}/component_losses.png\")\n",
    "    plt.close()\n",
    "\n",
    "def visualize_latent_space(latents, labels, variant, save_path=\"model_plots\"):\n",
    "    \"\"\"Visualize the latent space of a model using t-SNE.\"\"\"\n",
    "    latents_np = latents.numpy()\n",
    "    labels_np = np.array(labels)\n",
    "\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    latents_2d = tsne.fit_transform(latents_np)\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    scatter = plt.scatter(latents_2d[:,0], latents_2d[:,1], c=labels_np, cmap='viridis', s=10, alpha=0.8)\n",
    "    plt.colorbar(scatter, label='Class')\n",
    "    plt.title(f\"t-SNE of Latent Space ({variant})\")\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{save_path}/latent_space_{variant}.png\")\n",
    "    plt.close()\n",
    "\n",
    "def main(train_dataloader, val_dataloader, model_name=\"efficientnet_b0\", \n",
    "         latent_dim=128, num_classes=3, input_size=(3, 150, 150), num_epochs=10):\n",
    "    variants = [\n",
    "        {\"name\": \"baseline\", \"params\": {\"variant\": \"baseline\"}},\n",
    "        {\"name\": \"pde\", \"params\": {\"variant\": \"pde\", \"lambda_pde\": 0.1}},\n",
    "        {\"name\": \"energy\", \"params\": {\"variant\": \"energy\", \"lambda_energy\": 0.1}},\n",
    "        {\"name\": \"both\", \"params\": {\"variant\": \"both\", \"lambda_pde\": 0.1, \"lambda_energy\": 0.1}}\n",
    "    ]\n",
    "\n",
    "    all_histories = []\n",
    "    models = []\n",
    "    for variant in variants:\n",
    "        print(f\"\\n=== Training {variant['name']} variant ===\\n\")\n",
    "        model = AutoencoderClassifier(model_name=model_name, latent_dim=latent_dim, \n",
    "                                      num_classes=num_classes, input_size=input_size)\n",
    "        \n",
    "        model, history, latents, labels = train_variant(\n",
    "            model, train_dataloader, val_dataloader, \n",
    "            num_epochs=num_epochs, **variant[\"params\"]\n",
    "        )\n",
    "        models.append(model.state_dict())\n",
    "        \n",
    "        all_histories.append(history)\n",
    "\n",
    "        if latents is not None and len(latents) > 0:\n",
    "            visualize_latent_space(latents, labels, variant['name'])\n",
    "    \n",
    "    variant_names = [v[\"name\"] for v in variants]\n",
    "    plot_history(all_histories, variant_names)\n",
    "    \n",
    "    print(\"\\nTraining and visualization complete. Check the 'model_plots' directory for results.\")\n",
    "    return models\n",
    "\n",
    "models = main(train_loader, val_loader, num_epochs=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3d2313e-6d84-4e92-ad36-bb884075ffd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T14:47:12.082944Z",
     "iopub.status.busy": "2025-04-01T14:47:12.082588Z",
     "iopub.status.idle": "2025-04-01T14:47:12.526225Z",
     "shell.execute_reply": "2025-04-01T14:47:12.525359Z",
     "shell.execute_reply.started": "2025-04-01T14:47:12.082919Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for i,model in enumerate(models):\n",
    "    torch.save({\"model_state_dict\":model},f'autoencoder{i}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4d55e-fe83-4745-aa0d-03b2812b413b",
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6759693,
     "sourceId": 10879292,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
